---
title: Working with Postgres Row Level Security
description: Some notes based on my experience working with RLS policies in Postgres, with a particular focus on performance.
draft: true
---
Since 2016, Postgres has included a feature called [row security policies](https://www.postgresql.org/docs/current/ddl-rowsecurity.html), perhaps better known as row-level security (RLS) policies. RLS lets access to database tables be restricted on a per-row basis when executing a query. This is done through creating policies which act similarly to `where` clauses in SQL statements.

For example, instead of adding manually a `where` clause to a given query:

```sql
select * from users where user_id = 'current-user-id';
```

You can add a policy instead:

```sql
create policy "Users can only CRUD themselves."
  on users
  using (user_id = current_setting('user_id', true)::uuid);
```

Then, the following SQL query can be used, without having to be qualified with a `where` clause:

```sql
select * from users;
```

At face value, this might just seem like a convenience feature to avoid populating your codebase with restriction clauses. However, it can serve as a safeguard at the database level to ensure that the authorization rules for database access are strictly followed.

When coupled with tools like [PostgREST](https://postgrest.org/) and [PostGraphile](https://www.graphile.org/postgraphile/), simple REST/GraphQL APIs can be created automatically without requiring additional backend servers/layers for authorization logic. In fact, that's exactly what Supabase does[^1].

Using Postgres with RLS policies and autogenerated APIs is a great way to quickly develop without setting up a custom backend server when launching new products. However, as your user base scales up and your database grows, there's a tendency for RLS policies to cause unexpected performance characteristics and slow queries.

In this article, I'd like to go through some notes and considerations to be aware of when working with RLS. I'll vbe using an example schema to demonstrate the process of working with RLS. There's going to be a focus on query performance, particularly on `select` statements which are subject to RLS policies[^2]. All the code samples and explanations are correst as of Postgres v15.3. If you'd like, you can also skip straight to the [conclusion](#conclusion) for a list of actionable tips.

## Example schema {#schema}

I'm using a simplified version of a workspace-based multitenant application as an example. I won't be building out the full schema, but will reference specific parts for use when relevant. Here's our schema requirements:

- Users can belong to multiple workspaces.
- Each workspace can have multiple users (known as workspace members).
- All users can only access data for workspaces that they are members of.

First, we'll construct the required tables for `users`, `workspaces`, and `workspace_members`:

```sql
postgres=# create table users (
  id uuid primary key default gen_random_uuid(),
  name varchar(200) not null,
  email varchar(200) not null
);
CREATE TABLE

postgres=# create table workspaces (
  id uuid primary key default gen_random_uuid(),
  name varchar(200) not null
);
CREATE TABLE

-- `workspace_members` is a joining table to determine
-- which workspaces users can access.
postgres=# create table workspace_members (
  id uuid primary key default gen_random_uuid(),
  workspace_id uuid not null references workspaces(id),
  user_id uuid not null references users(id),
  type varchar(20) not null check (type = 'member' or type = 'admin')
);
CREATE TABLE
```

Then, populate the database with random data of sufficient size to simulate an app which has grown in popularity:

```sql
postgres=# with
users as (
  -- Create 100000 users.
  insert into users (name, email)
  select
  'Placeholder user ' || i,
  'placeholder@email' || (i % 10) || '.com'
  from generate_series(1, 100000) i
  returning *
),
workspaces as (
  -- Create 40000 workspaces.
  insert into workspaces (name)
  select 'Workspace ' || i
  from generate_series(1, 40000) i
  returning *
)
-- Add 5 random users as members of each workspace.
insert into workspace_members (workspace_id, user_id, type)
select
  workspaces.id,
  (select users.id from users where i = i offset floor(random() * 100000) limit 1),
  'member'
from workspaces, generate_series(1, 5) i;
INSERT 0 200000
```

## Enabling RLS

Prior to working on the actual RLS policies, we have to do some basic setup. First, we'll start by creating a new role, then enabling RLS on the three tables. The new role will be subject to RLS policies by default.

```sql
postgres=# create role authenticated_user;
CREATE ROLE

postgres=# grant select
  on users, workspaces, workspace_members
  to authenticated_user;
GRANT

postgres=# alter table users enable row level security;
ALTER TABLE

postgres=# alter table workspaces enable row level security;
ALTER TABLE

postgres=# alter table workspace_members enable row level security;
ALTER TABLE
```

This `authenticated_user` role is used to execute queries, and is unable to bypass RLS. We'll run queries in transactions, using the local `user_id` setting to represent the currently authenticated user. RLS policies can then refer to `current_setting('rls.user_id', true)::uuid` to access the currently authenticated user's ID.

```sql
postgres=# begin;
-- Run transaction with `authenticated_user` role,
-- and setting `user_id` as the current user's ID.
set local role authenticated_user;
-- I picked a random user ID based on the random data,
-- which belonged to 3 workspaces.
set local "rls.user_id" to 'a74c6f1e-b6ac-4088-b468-6c1987146721';

-- Reads the current setting for `user_id` and converts to UUID format.
select current_setting('rls.user_id', true)::uuid;
end;
BEGIN
SET
SET
         current_setting
--------------------------------------
 a74c6f1e-b6ac-4088-b468-6c1987146721
(1 row)

COMMIT
```

In Supabase, this can be done using the [`auth.uid()`](https://supabase.com/docs/guides/auth/row-level-security#authuid) function.

## Performance analysis {#performance}

Since I'm going to be talking about query performance, it's a good idea to be familiar with using [`explain (analyze)`](https://www.postgresql.org/docs/current/using-explain.html) to run queries. When running `explain (analyze)`, we also need to make sure to run queries in the role for which RLS policies are enabled, to get an accurate understanding of performance:

```sql
postgres=# begin;
set local role authenticated_user;
set local "rls.user_id" to 'a74c6f1e-b6ac-4088-b468-6c1987146721';

explain analyze select * from users;
end;
BEGIN
SET
SET
                                   QUERY PLAN
------------------------------------------------------------------------------------
 Result  (cost=0.00..0.00 rows=0 width=0) (actual time=0.001..0.001 rows=0 loops=1)
 One-Time Filter: false
 Planning Time: 0.049 ms
 Execution Time: 0.102 ms
(4 rows)

COMMIT
```

As you can see, now that we've enabled RLS, selecting from the `users` table will not return any results (`rows=0`) until we've added policies.

If you're interested, there's also [a series of articles](https://www.depesz.com/tag/unexplainable/) providing an overview of the more common nodes encountered in query plans.

## Always add indices to appropriate columns {#indices}

Okay, this tip isn't really something that's specific to RLS policies, but just something that's important to reiterate if you're worried about query performance: You should always check that you have appropriate indices added to your tables for columns which are commonly filtered by, or are used as a join condition. This might be crucial for columns with foreign key references[^3], which do not have indices created on them by default.

## Creating policies

We'll start off simple by [defining a policy](https://www.postgresql.org/docs/current/sql-createpolicy.html) for `select`ing from `workspace_members` . The policy uses an `exists` subquery expression to check if there is a shared workspace between the row being checked and the current user:

```sql
postgres=#
-- Users are in the same workspace if there exists a `workspace_members` row
-- for the current user that has the same workspace ID as the current
-- `workspace_members` row being checked.
create policy "Users can view members in their workspaces"
on workspace_members
for select
using (exists (
  select 1 from workspace_members auth_user_workspace_members
  where auth_user_workspace_members.workspace_id = workspace_members.workspace_id
  and auth_user_workspace_members.user_id = current_setting('rls.user_id', true)::uuid
));
CREATE POLICY
```

Next, we'll do a quick test to check if the policy is working:

```sql
postgres=# begin;
set local role authenticated_user;
set local "rls.user_id" to 'a74c6f1e-b6ac-4088-b468-6c1987146721';

select * from workspace_members;
end;
BEGIN
SET
SET
ERROR:  infinite recursion detected in policy for relation "workspace_members"

ROLLBACK
```

## Security definer functions to avoid recursive policies {#security-definer-functions}

As the error shows, the current policy is flawed. The policy for `workspace_members` references `workspace_members` itself, causing a recursive reference which Postgres cannot resolve. This is a common issue when trying to define policies: some tables, especially junction tables, need recursive access to their own data to determine whether access to specific rows should be allowed.

The workaround here is for a role with the `bypassrls` attribute to [create a security definer function](https://www.postgresql.org/docs/current/sql-createfunction.html) for use within the policy. Security definer functions always execute in the context of the user who defined the function. If a role with the `bypassrls` attribute has created a security definer function, the created function can access the `workspace_members` table whilst bypassing the RLS policies, even when executed by a role that is subject to RLS policies. This allows the infinite recursion to be avoided!

Here's a very contrived and non-performant example of a security definer function and its associated policy:

```sql
postgres=#
-- Returns `true` if the given user can access the given worksapce.
create function can_user_view_workspace(_user_id uuid, _workspace_id uuid)
returns boolean language sql as $$
select exists (
  select 1
  from workspace_members
  -- Note: function arguments cannot be defined with the same name as column names,
  -- otherwise Postgres will just compare the column's value to itself,
  -- which is always `true`.
  where user_id = _user_id
  and workspace_id = _workspace_id
)
$$ security definer;
CREATE FUNCTION

postgres=# alter policy "Users can view members in their workspaces"
on workspace_members
using (can_user_view_workspace(current_setting('rls.user_id', true)::uuid, workspace_id));
ALTER POLICY
```

We'll also create indices on the `user_id` and `workspace_id` column since they are being searched:

```sql
postgres=# create index on workspace_members (workspace_id);
CREATE INDEX
postgres=# create index on workspace_members (user_id);
CREATE INDEX
```

Now, let's check if our new policies work:

```sql
postgres=# begin;
set local role authenticated_user;
set local "rls.user_id" to 'a74c6f1e-b6ac-4088-b468-6c1987146721';

select * from workspace_members;
end;
BEGIN
SET
SET
                  id                  |             workspace_id             |               user_id                |  type
--------------------------------------+--------------------------------------+--------------------------------------+--------
 63a19196-e2e7-46c6-ad49-14754ec0e1a9 | 163175a5-5a6e-40a7-86a1-8ed2cd15e790 | a74c6f1e-b6ac-4088-b468-6c1987146721 | member
 3e801fad-a4d8-4809-979f-8c0288cce7e7 | 07267681-62ac-4216-94bc-f1219784cee8 | a74c6f1e-b6ac-4088-b468-6c1987146721 | member
 aa0800e0-eaab-4053-9275-0504bb8223a6 | 3e51bd81-5432-4bd7-bdfc-95f8a69c3d39 | 3c1f86d4-b6bb-4a37-9398-27b59462aea2 | member
 08490a49-29fe-4785-aa07-457eaf49e304 | 163175a5-5a6e-40a7-86a1-8ed2cd15e790 | 544c115d-e537-4c83-9873-e2adc5b4cb05 | member
 a028c4fc-e943-48e3-96ae-b3d05edb04b5 | 07267681-62ac-4216-94bc-f1219784cee8 | 4a274a1f-a371-4bec-a173-465454719b89 | member
 114aa55c-8a70-40cf-8848-3e10a7684ff7 | 3e51bd81-5432-4bd7-bdfc-95f8a69c3d39 | 5442108f-754e-4bb3-8d3a-34e0fbcdc15a | member
 9ce2acf4-ae7d-4d9d-b5c8-1fa3c1f1518d | 163175a5-5a6e-40a7-86a1-8ed2cd15e790 | a4684dd6-b4a3-4046-8ad0-56a945a82933 | member
 2821012d-0062-4b56-9b7c-adbdeb19c033 | 07267681-62ac-4216-94bc-f1219784cee8 | 0926427b-bac4-448d-88c4-af2f725138e2 | member
 0ef43990-1f58-4b56-bb41-96e7f6fe0a8c | 3e51bd81-5432-4bd7-bdfc-95f8a69c3d39 | 3f06a03a-fa17-4ea5-986f-c351a39e61f6 | member
 11c935e3-cfb0-4bcf-bad6-6992b5a415a2 | 163175a5-5a6e-40a7-86a1-8ed2cd15e790 | 605bb650-85c2-43f1-a60b-f2ef372429df | member
 9ea6cafb-35d7-4866-8427-70814ccc6240 | 07267681-62ac-4216-94bc-f1219784cee8 | 0757c17e-ac99-45cc-906b-61028144e41c | member
 b165559a-442a-4ebd-ad66-cdcdd67ea8c6 | 3e51bd81-5432-4bd7-bdfc-95f8a69c3d39 | a74c6f1e-b6ac-4088-b468-6c1987146721 | member
 5c3bd18a-a431-4d53-b6e6-996aefdaa421 | 163175a5-5a6e-40a7-86a1-8ed2cd15e790 | c8b56041-d082-4b52-93b7-84ed8a4accdb | member
 1bdc38d3-7d2b-42e3-b432-11e8f4b348a0 | 07267681-62ac-4216-94bc-f1219784cee8 | 7e53016a-1454-4e2c-893e-97d2c1bab269 | member
 8c11bbe0-54f5-4628-9df1-ea70b7a9334f | 3e51bd81-5432-4bd7-bdfc-95f8a69c3d39 | b929aef8-b0db-4260-91e7-271f50939025 | member

(15 rows)
COMMIT
```

Yay, it works! So, security definer functions can be used to avoid the infinite policy recursion. Postgres functions might appear similar to functions in other languages, but there are certain pitfalls when it comes to using them. Let's go through some of them.

## Do not accept column values as function parameters {#function-parameters}

Here's a look at the query plan of the previous query:

```sql
postgres=# begin;
set local role authenticated_user;
set local "rls.user_id" to 'a74c6f1e-b6ac-4088-b468-6c1987146721';

explain analyze select * from workspace_members;
end;
BEGIN
SET
SET
                                                     QUERY PLAN
-------------------------------------------------------------------------------------------------------------------------
 Seq Scan on workspace_members  (cost=0.00..55562.00 rows=66667 width=55) (actual time=71.550..1618.279 rows=15 loops=1)
 Filter: can_user_view_workspace((current_setting('rls.user_id'::text, true))::uuid, workspace_id)
 Rows Removed by Filter: 199985
 Planning Time: 0.683 ms
 Execution Time: 1618.319 ms
(5 rows)

COMMIT
```

Even though the result only contains 15 rows, the generated query plan performs a sequential scan on the `workspace_members` table. The thing is, even a typical sequential scan on a large table shouldn't be taking so long (1.6 seconds)! What's happening here is that for each row in the table, Postgres has to do a function call to check if the RLS policy is satisfied. Typically, one or two function calls per query is not expensive, but here we're executing up to 200,000 function calls, each of which return the results of their own queries. The cost of switching between the current query and the invoked function's context adds up, resulting in a really slow query.

Instead, policies should be restructured to avoid running a function for every row in the table. A common pattern would be to use the function to get a list of identifiers for valid rows in the current table, then check if the current row is a valid row in the policy.

For `workspace_members` here, this would mean getting the list of workspace IDs which a user has access to, and check if the current row in `workspace_members` belongs to one of those workspaces:

```sql
postgres=#
-- Returns the set of accessible workspaces for the authenticated user.
create or replace function get_workspaces_for_auth_user()
returns setof uuid language sql as $$
select workspace_id
from workspace_members
where user_id = current_setting('rls.user_id', true)::uuid
$$ security definer;
CREATE FUNCTION

-- Update the policy to use the new function.
postgres=# alter policy "Users can view members in their workspaces"
on workspace_members
using (workspace_id in (select get_workspaces_for_auth_user()));
ALTER POLICY

-- Get rid of the old function.
postgres=# drop function can_user_view_workspace(uuid, uuid);
DROP FUNCTION
```

Here's the updated query plan:

```sql
postgres=# begin;
set local role authenticated_user;
set local "rls.user_id" to 'a74c6f1e-b6ac-4088-b468-6c1987146721';

explain analyze select * from workspace_members;
end;
BEGIN
SET
SET
                                                    QUERY PLAN
----------------------------------------------------------------------------------------------------------------------
 Seq Scan on workspace_members  (cost=7.77..4569.76 rows=100000 width=55) (actual time=3.933..22.933 rows=15 loops=1)
 Filter: (hashed SubPlan 1)
 Rows Removed by Filter: 199985
 SubPlan 1
   ->  ProjectSet  (cost=0.00..5.27 rows=1000 width=16) (actual time=2.180..2.189 rows=3 loops=1)
         ->  Result  (cost=0.00..0.01 rows=1 width=0) (actual time=0.001..0.001 rows=1 loops=1)
 Planning Time: 0.623 ms
 Execution Time: 23.842 ms
(8 rows)

COMMIT
```

Now, instead of running the function once per row, we're executing the function and retrieveing matching workspace IDs once, and storing them in a hash table. This speeds up the outer sequential scan greatly, since checking the hash table for each row is much cheaper than executing a function.

## Use uncorrelated subqueries when possible {#uncorrelated-subqueries}

[Subqueries](https://www.postgresql.org/docs/current/functions-subquery.html) are nested `select` statements within the main SQL statement. Uncorrelated subqueries are subqueries which do not depend on any columns in the outer query. In the previous example, the subquery in the policy is an uncorrelated subquery, since `select get_workspaces_for_auth_user()` does not reference any columns in the outer query.

Using uncorrelated subqueries can allow the subquery to be extracted out into an [`InitPlan`](https://www.depesz.com/2013/05/19/explaining-the-unexplainable-part-4/#init-plan) node by the query planner. `InitPlan` nodes are executed once at the start of a query, and have their results stored for use by other nodes in the query plan. They are especially useful for boolean conditions: eg. if a query depends solely on a boolean which is returned by an uncorrelated subquery, the whole query can just be skipped when the boolean returns `false`.

In practice, this might mean wrapping your function queries in an additional `select` statement, even if they are equivalent:

```sql
-- Before:
create policy "Admins can CRUD all workspaces"
on workspaces
using (is_admin());

-- After:
create policy "Admins can CRUD all workspaces"
on workspaces
using (select is_admin());
```

This ties in well with the previous point: If your functions are written so that they don't depend on column values from the table being policed, they can be used as an uncorrelated subquery.

Note that not all uses of uncorrelated subqueries can be converted into `InitPlan`s. We'll take a look at some specifics later.

## Be as specific as possible when defining security definer functions {#function-definitions}

When [creating security definer functions](https://www.postgresql.org/docs/current/sql-createfunction.html), you should be as accurate as possible with the function definition. In particular, there are two properties you should always specify: the function volatility category and the number of rows returned.

By default, functions are assumed to be `volatile`:

  > A query using a volatile function will re-evaluate the function at every row where its value is needed.
  > — <cite>[PostgreSQL Documentation: Function Volatility Categories](https://www.postgresql.org/docs/current/xfunc-volatility.html)</cite>

If you can't use the function in an uncorrelated subquery, using a volatile function might cause the function to be called multiple times in a given query, even if you know that the query results do not change. Instead, mark the function as `stable`:

  > A STABLE function cannot modify the database and is guaranteed to return the same results given the same arguments for all rows within a single statement. This category allows the optimizer to optimize multiple calls of the function to a single call. In particular, it is safe to use an expression containing such a function in an index scan condition. (Since an index scan will evaluate the comparison value only once, not once at each row, it is not valid to use a VOLATILE function in an index scan condition.)
  > — <cite>[PostgreSQL Documentation: Function Volatility Categories](https://www.postgresql.org/docs/current/xfunc-volatility.html)</cite>

Functions which return sets/rows are also implicitly defined to return 1000 rows by default. This is not accurate for all use cases, and should be updated to provide a more accurate representation. Using the example schema above, it's quite likely that a user will never be part of more than 10 workspaces. Hence, we can update the `get_workspaces_for_auth_user()` function to be `stable` and have `rows 10`:

```sql
postgres=#
-- Returns the set of accessible workspaces for the authenticated user.
create or replace function get_workspaces_for_auth_user()
returns setof uuid language sql as $$
select workspace_id
from workspace_members
where user_id = current_setting('rls.user_id', true)::uuid
$$ security definer
-- UPDATED!
stable rows 10;
CREATE FUNCTION
```

Just changing the row estimates might not directly lead to a faster query plan, but it provides more visibility to the query planner on the results of the function. This change might be more useful if the functions are being used elsewhere (apart from RLS policies).

Another possible modification, with a greater degree of risk, is to manually specify the estimated cost of the function. For example, if you're using a function which cannot be extracted into a uncorrelated subquery, and the query plan shows that the function is being repeatedly called even though a single call would be sufficient, setting the function's cost as a high enough value might prompt the query planner to only call the function once. This tweak is particularly risky since the cost estimates for a query can change drastically over time as the dataset changes. **Only do this if you're aware of the potential drawbacks.**

## Be careful when adding multiple policies to the same table {#multiple-policies}

There are two different types of RLS policies:
1. permissive policies (the default), which are combined using `or`; and
1. restrictive policies, which are combined using `and`.

It's convenient to add multiple permissive policies which get joined together using `or` . However, `or` conditions are much harder to optimize than `and` conditions: `and` conditions restrict the size of the query output while `or` conditions increase the size of the query output.

Depending on the database schemas, sometimes there isn't a choice on whether to use an `or` condition to perform RLS policy checks, such as if the checks are on different columns. However, if you're using multiple policies to perform checks on the same column, especially if you're using multiple function calls, it's generally cheaper to combine them into a single check:

```sql
-- Before:
create policy "Users can CRUD all of their workspaces"
on workspaces
using (id in (select get_workspaces_for_auth_user()));

create policy "Users can CRUD globally editable workspaces"
on workspaces
using (id in (select get_globally_editable_workspaces()));

-- After:
create policy "Users can CRUD their own and globally editable workspaces"
on workspaces
using (
  id in (
    select get_workspaces_for_auth_user()
    union all
    select get_globally_editable_workspaces()
  )
);
```

## Non-leakproof functions and operators causes can prevent index scans {#non-leakproof}

Using functions and operators which are not leakproof can prevent index scans from being performed, and cause fallback to slower scan types:

  > LEAKPROOF indicates that the function has no side effects. It reveals no information about its arguments other than by its return value. For example, a function which throws an error message for some argument values but not others, or which includes the argument values in any error message, is not leakproof. This affects how the system executes queries against views created with the security_barrier option or tables with row level security enabled. The system will enforce conditions from security policies and security barrier views before any user-supplied conditions from the query itself that contain non-leakproof functions, in order to prevent the inadvertent exposure of data. Functions and operators marked as leakproof are assumed to be trustworthy, and may be executed before conditions from security policies and security barrier views. In addition, functions which do not take arguments or which are not passed any arguments from the security barrier view or table do not have to be marked as leakproof to be executed before security conditions.
  > — <cite>[PostgreSQL Documentation: CREATE FUNCTION](https://www.postgresql.org/docs/current/sql-createfunction.html)</cite>

If a query condition uses a non-leakproof function/operator, and there is an active RLS policy, it might prevent the condition from using an index it would otherwise have used.

For example, let's allow users to seach for others by name. We'll create a GIN index with the `pg_trgm` extension to allow to optimize this query. However, we'll also add an RLS policy to restrict which users can be seen.

```sql
postgres=# create extension pg_trgm;
CREATE EXTENSION

postgres=# create index on users using gin (name gin_trgm_ops);
CREATE INDEX

postgres=#
-- Returns the set of accessible users for the authenticated user.
create or replace function get_visible_users_for_auth_user()
returns setof uuid language sql as $$
select user_id
from workspace_members
where workspace_id in (select get_workspaces_for_auth_user());
$$ security definer
stable rows 30;
CREATE FUNCTION

postgres=# create policy "Users have access restricted based on a random policy"
on users
using (id in (select get_visible_users_for_auth_user()));
CREATE POLICY
```

Here's the result of the query made by a role without the `bypassrls` attribute:

```sql
postgres=# begin;
set local role authenticated_user;
set local "rls.user_id" to 'a74c6f1e-b6ac-4088-b468-6c1987146721';

explain analyze
  select * from users
  where name ilike '%test';
end;
BEGIN
SET
SET
                                            QUERY PLAN
------------------------------------------------------------------------------------------------------
 Seq Scan on users  (cost=0.49..2637.49 rows=80 width=61) (actual time=29.900..29.901 rows=0 loops=1)
 Filter: ((hashed SubPlan 1) AND ((name)::text ~~* '%test'::text))
 Rows Removed by Filter: 100000
 SubPlan 1
   ->  ProjectSet  (cost=0.00..0.42 rows=30 width=16) (actual time=5.879..5.960 rows=15 loops=1)
         ->  Result  (cost=0.00..0.01 rows=1 width=0) (actual time=0.001..0.001 rows=1 loops=1)
 Planning Time: 0.150 ms
 Execution Time: 30.496 ms
(8 rows)

COMMIT
```

Compare this to a query made by a role with the `bypassrls` attribute, which **will** use the index:

```sql
postgres=# begin;
set local "rls.user_id" to 'a74c6f1e-b6ac-4088-b468-6c1987146721';

explain analyze
select * from users
  where name ilike '%test'
  and id in (select get_visible_users_for_auth_user());
end;
BEGIN
SET
                                                        QUERY PLAN
-------------------------------------------------------------------------------------------------------------------------------
 Hash Semi Join  (cost=29.17..66.51 rows=1 width=61) (actual time=0.249..0.287 rows=0 loops=1)
 Hash Cond: (users.id = (get_visible_users_for_auth_user()))
 ->  Bitmap Heap Scan on users  (cost=28.08..65.39 rows=10 width=61) (actual time=0.044..0.044 rows=0 loops=1)
       Recheck Cond: ((name)::text ~~* '%test'::text)
       ->  Bitmap Index Scan on users_name_idx  (cost=0.00..2      -8.07 rows=10 width=0) (actual time=0.043..0.044 rows=0 loops=1)
             Index Cond: ((name)::text ~~* '%test'::text)
 ->  Hash  (cost=0.72..0.72 rows=30 width=16) (actual time=0.202..0.203 rows=15 loops=1)
       Buckets: 1024  Batches: 1  Memory Usage: 9kB
       ->  ProjectSet  (cost=0.00..0.42 rows=30 width=16) (actual time=0.176..0.200 rows=15 loops=1)
             ->  Result  (cost=0.00..0.01 rows=1 width=0) (actual time=0.001..0.001 rows=1 loops=1)
 Planning Time: 0.231 ms
 Execution Time: 0.305 ms
(12 rows)

COMMIT
```

With RLS enabled, the query is unable to use the index since the underlying function for the `ilike` operator is not leakproof.

To check if a specific operator might fall victim to this issue, you can:

1. Get the underlying function called by the operator:
    ```sql
    postgres=# select
    oprname,
    pg_type_left.typname as left_opr_type,
    pg_type_right.typname as right_opr_type,
    oprcode
    from pg_operator
    left join pg_type pg_type_left on pg_operator.oprleft = pg_type_left.oid
    left join pg_type pg_type_right on pg_operator.oprright = pg_type_right.oid
    where oprname = '~~*';

    oprname | left_opr_type | right_opr_type |   oprcode
    ---------+---------------+----------------+--------------
    ~~*     | name          | text           | nameiclike
    ~~*     | text          | text           | texticlike
    ~~*     | bpchar        | text           | bpchariclike
    (3 rows)
    ```

1. Then check if the function is leakproof:
    ```sql
    postgres=# select proname, prosrc, proleakproof
    from pg_proc
    where proname = 'texticlike';

    proname   |   prosrc   | proleakproof
    ------------+------------+--------------
    texticlike | texticlike | f
    (1 row)
    ```

This optimization barrier means that many of the more unconventional index types might not be used when using RLS. Thankfully, more common operators like `=`, `<` and `>` used by B-tree and hash indices are leakproof, so these common index types can still be used.

A potential workaround would be to modify the underlying function to make it leakproof:

```sql
postgres=# alter function texticlike leakproof;
ALTER FUNCTION

postgres=# begin;
set local role authenticated_user;
set local "rls.user_id" to 'a74c6f1e-b6ac-4088-b468-6c1987146721';

explain analyze select * from users where name ilike '%test';
end;
BEGIN
SET
SET
                                                     QUERY PLAN
-------------------------------------------------------------------------------------------------------------------------
 Bitmap Heap Scan on users  (cost=28.57..65.90 rows=5 width=61) (actual time=0.022..0.036 rows=0 loops=1)
 Recheck Cond: ((name)::text ~~* '%test'::text)
 Filter: (hashed SubPlan 1)
 ->  Bitmap Index Scan on users_name_idx  (cost=0.00..28.07 rows=10 width=0) (actual time=0.008..0.009 rows=0 loops=1)
       Index Cond: ((name)::text ~~* '%test'::text)
 SubPlan 1
   ->  ProjectSet  (cost=0.00..0.42 rows=30 width=16) (never executed)
         ->  Result  (cost=0.00..0.01 rows=1 width=0) (never executed)
 Planning Time: 0.167 ms
 Execution Time: 0.071 ms
(10 rows)

COMMIT
```

After modifying the function's `leakproof` attribute, the `ilike` comparison is performed first within the query, allowing the index on `users.name` to be used. Modifying the `leakproof` attribute requires superuser access, and can potentially lead to data leakages, so **only do this if you're aware of the potential drawbacks.**

## Optimizing queries

If you've been looking carefully at the query plans for the `workspace_members` queries, you might notice that they've all being performing sequential scans and scanning the whole table:

```sql
postgres=# begin;
set local role authenticated_user;
set local "rls.user_id" to 'a74c6f1e-b6ac-4088-b468-6c1987146721';

explain analyze select * from workspace_members;
end;
BEGIN
SET
SET
                                                   QUERY PLAN
---------------------------------------------------------------------------------------------------------------------
 Seq Scan on workspace_members  (cost=0.34..913.34 rows=20000 width=55) (actual time=18.741..22.529 rows=60 loops=1)
 Filter: (hashed SubPlan 1)
 Rows Removed by Filter: 39940
 SubPlan 1
   ->  ProjectSet  (cost=0.00..0.32 rows=10 width=16) (actual time=5.582..18.621 rows=3 loops=1)
         ->  Result  (cost=0.00..0.01 rows=1 width=0) (actual time=0.000..0.001 rows=1 loops=1)
 Planning Time: 0.087 ms
 Execution Time: 22.562 ms
(8 rows)

COMMIT
```

Let's try to compare this by switching to a role that bypasses RLS:

```sql
postgres=# begin;
-- Set the RLS user ID as a setting so that the `get_workspaces_for_auth_user()`
-- function works, but still bypass RLS by not switching users.
set local "rls.user_id" to 'a74c6f1e-b6ac-4088-b468-6c1987146721';

explain analyze select * from workspace_members;
end;
BEGIN
SET
                                                        QUERY PLAN
-------------------------------------------------------------------------------------------------------------------------------
 Hash Semi Join  (cost=29.17..66.51 rows=1 width=61) (actual time=0.234..0.235 rows=0 loops=1)
 Hash Cond: (users.id = (get_visible_users_for_auth_user()))
 ->  Bitmap Heap Scan on users  (cost=28.08..65.39 rows=10 width=61) (actual time=0.007..0.007 rows=0 loops=1)
       Recheck Cond: ((name)::text ~~* '%test'::text)
       ->  Bitmap Index Scan on users_name_idx  (cost=0.00..28.07 rows=10 width=0) (actual time=0.007..0.007 rows=0 loops=1)
             Index Cond: ((name)::text ~~* '%test'::text)
 ->  Hash  (cost=0.72..0.72 rows=30 width=16) (actual time=0.225..0.225 rows=15 loops=1)
       Buckets: 1024  Batches: 1  Memory Usage: 9kB
       ->  ProjectSet  (cost=0.00..0.42 rows=30 width=16) (actual time=0.199..0.223 rows=15 loops=1)
             ->  Result  (cost=0.00..0.01 rows=1 width=0) (actual time=0.001..0.001 rows=1 loops=1)
 Planning Time: 0.202 ms
 Execution Time: 0.254 ms
(12 rows)

COMMIT
```

You can see that the query made by this role skips the full sequential scan in favor of using the index for a bitmap index scan. There's effectively no difference between the two queries, except one is executed with RLS policies enabled and the other disabled.

Let's take a quick exploration through the Postgres source code to figure out what happens here. Normal conditions in the `where` clause, known as quals, will go through the [`pull_up_sublinks` function](https://github.com/postgres/postgres/blob/8382864eb5c9f9ebe962ac20b3392be5ae304d23/src/backend/optimizer/prep/prepjointree.c#L260-L289). `pull_up_sublinks` rewrites certain subquery expressions (referred to as sublinks) to "pull them up" from `where` conditions to become relations to be `join`ed. In particular, it rewrites certain queries using sublinks to convert them to their equivalent joins:
- The [`convert_ANY_sublink_to_join` function](https://github.com/postgres/postgres/blob/8382864eb5c9f9ebe962ac20b3392be5ae304d23/src/backend/optimizer/plan/subselect.c#L1233-L1269) converts the following sublinks to their equivalent joins:
  - `lhs op any (select ...)`
  - `lhs in (select ...)` (This is treated as a variant of the `any` subquery.)
- The [`convert_EXISTS_sublink_to_join` function](https://github.com/postgres/postgres/blob/8382864eb5c9f9ebe962ac20b3392be5ae304d23/src/backend/optimizer/plan/subselect.c#L1368-L1377) converts the following sublinks to their equivalent joins:
  - `exists (select ...)`
  - `not exists (select ...)`

Rewriting of subquery expressions into join operations is helpful because it can convert the operations into [semi join and anti join node types](https://blog.jooq.org/semi-join-and-anti-join-should-have-its-own-syntax-in-sql/). Semi joins and anti joins are specialized variants of join operations which can utilize more optimized access patterns when generating the query plan. However, RLS policies are not treated as normal quals. They are treated as specialized quals known as security quals, and are subject to more stringent data access requirements to prevent data leakage. They do not have the `pull_up_sublinks` operation performed on them, so they aren't rewritten into more optimal joins, and are stuck with using a sequential scan across the whole table. Although some optimizations are still performed[^4], this is still less performant than the equivalent.

This is very much a problem, because most RLS policies are typically expressed using either the `any` or `exists` subquery patterns.

### Optimizing `any` subqueries

Both the `lhs op any (select ...)` and `lhs in (select ...)` forms of `any` subqueries are represented by the same nodes in the database, which cannot be optimized when used in a RLS policy. However, if you're familiar with Postgres, you might be aware of one more use of the `any` keyword: they can also be used for [comparisons with arrays](https://www.postgresql.org/docs/current/functions-comparisons.html#id-1.5.8.30.16):

```sql
select * from users where email = any(array['value@email.com']);
```

We can rewrite our existing `any` subquery to use the new array comparison operator form:

```sql
postgres=# alter policy "Users can view members in their workspaces"
on workspace_members
using (workspace_id = any(array(select get_workspaces_for_auth_user())));
ALTER POLICY

postgres=# begin;
set local role authenticated_user;
set local "rls.user_id" to 'a74c6f1e-b6ac-4088-b468-6c1987146721';

explain analyze select * from workspace_members;
end;
BEGIN
SET
SET
                                                                QUERY PLAN
----------------------------------------------------------------------------------------------------------------------------------------------
 Bitmap Heap Scan on workspace_members  (cost=44.90..219.34 rows=49 width=55) (actual time=1.681..1.733 rows=15 loops=1)
 Recheck Cond: (workspace_id = ANY ($0))
 Heap Blocks: exact=15
 InitPlan 1 (returns $0)
   ->  ProjectSet  (cost=0.00..0.32 rows=10 width=16) (actual time=0.100..0.105 rows=3 loops=1)
         ->  Result  (cost=0.00..0.01 rows=1 width=0) (actual time=0.000..0.001 rows=1 loops=1)
 ->  Bitmap Index Scan on workspace_members_workspace_id_idx  (cost=0.00..44.58 rows=49 width=0) (actual time=1.677..1.678 rows=15 loops=1)
       Index Cond: (workspace_id = ANY ($0))
 Planning Time: 0.218 ms
 Execution Time: 1.750 ms
(10 rows)

COMMIT
```

That's much better! We've managed to convert the sequential scan into the same bitmap heap scan used by the superuser! What happened here is that the `array(select get_workspaces_for_auth_user())` expression was represented in the query plan as a different array sublink type, with an uncorrelated subquery. This allowed a [different optimization to be performed](https://github.com/postgres/postgres/blob/8382864eb5c9f9ebe962ac20b3392be5ae304d23/src/backend/optimizer/plan/subselect.c#L375-L385) to convert the subquery into an `InitPlan`. The sequential scan can then be replaced with a straightforward index scan to find the rows satisfying the comparison with the result of the `InitPlan`.

### Optimizing `exists` subqueries

The other common type of subquery used in RLS policies are `exists` subqueries. Let's modify our schema so that we add an exists subquery. We'll add an RLS policy for `users` so that users can view other users who are in the same workspaces. We're also taking advantage of the fact that `workspace_members` has its own RLS policies applied, so we don't have to add any other filtering clauses for the `workspace_members` subquery:

```sql
postgres=# drop policy "Users have access restricted based on some random policy"
on users;
DROP POLICY

postgres=# create policy "Users can view users who are in thier workspaces"
on users for select
using (exists (
  select 1 from workspace_members
  where workspace_members.user_id = users.id
));
CREATE POLICY
```

Then, we'll try to execute a query on all `users` with RLS policies enabled:

```sql
postgres=# begin;
set local role authenticated_user;
set local "rls.user_id" to 'a74c6f1e-b6ac-4088-b468-6c1987146721';

explain analyze select * from users;
end;
BEGIN
SET
SET
                                                                    QUERY PLAN
------------------------------------------------------------------------------------------------------------------------------------------------------
 Seq Scan on users  (cost=0.00..1651083.19 rows=50000 width=61) (actual time=0.161..11.976 rows=13 loops=1)
 Filter: (hashed SubPlan 4)
 Rows Removed by Filter: 99987
 SubPlan 4
   ->  Bitmap Heap Scan on workspace_members  (cost=44.90..219.34 rows=49 width=16) (actual time=0.013..0.029 rows=15 loops=1)
         Recheck Cond: (workspace_id = ANY ($3))
         Heap Blocks: exact=15
         InitPlan 3 (returns $3)
           ->  ProjectSet  (cost=0.00..0.32 rows=10 width=16) (actual time=0.093..0.101 rows=3 loops=1)
                 ->  Result  (cost=0.00..0.01 rows=1 width=0) (actual time=0.000..0.001 rows=1 loops=1)
         ->  Bitmap Index Scan on workspace_members_workspace_id_idx  (cost=0.00..44.58 rows=49 width=0) (actual time=0.010..0.010 rows=15 loops=1)
               Index Cond: (workspace_id = ANY ($3))
 Planning Time: 0.113 ms
 Execution Time: 12.009 ms
(14 rows)

COMMIT
```

We're performing a sequential scan on all `users`, then checking each row if there is a matching `workspace_members` row. There doesn't appear to be any easy way to optimize the `exists` subquery here, as there was for the `any` subquery.

However, we can make use of some knowledge of Postgres's handling of RLS policies to help us. Normal quals can be executed before security quals if the normal quals use [non-leakproof operators or functions](#non-leakproof). Since the `exists` subquery in the security qual cannot be further rewritten into a more optimal form to use an index scan, we can attempt to add normal quals which **can** be optimized. The easiest one is just an additional `where` condition with a simple equality comparison:

```sql
postgres=# begin;
set local role authenticated_user;
set local "rls.user_id" to 'a74c6f1e-b6ac-4088-b468-6c1987146721';

explain analyze
  select * from users
  where id = 'a74c6f1e-b6ac-4088-b468-6c1987146721';
end;
BEGIN
SET
SET
                                                                QUERY PLAN
----------------------------------------------------------------------------------------------------------------------------------------------
 Index Scan using users_pkey on users  (cost=0.42..24.92 rows=1 width=61) (actual time=0.108..0.109 rows=1 loops=1)
 Index Cond: (id = 'a74c6f1e-b6ac-4088-b468-6c1987146721'::uuid)
 Filter: (SubPlan 2)
 SubPlan 2
   ->  Bitmap Heap Scan on workspace_members  (cost=4.76..16.49 rows=1 width=0) (actual time=0.090..0.090 rows=1 loops=1)
         Recheck Cond: (user_id = users.id)
         Filter: (workspace_id = ANY ($1))
         Heap Blocks: exact=1
         InitPlan 1 (returns $1)
           ->  ProjectSet  (cost=0.00..0.32 rows=10 width=16) (actual time=0.070..0.077 rows=3 loops=1)
                 ->  Result  (cost=0.00..0.01 rows=1 width=0) (actual time=0.000..0.001 rows=1 loops=1)
         ->  Bitmap Index Scan on workspace_members_user_id_idx  (cost=0.00..4.44 rows=3 width=0) (actual time=0.007..0.007 rows=3 loops=1)
               Index Cond: (user_id = users.id)
 Planning Time: 0.107 ms
 Execution Time: 0.132 ms
(15 rows)

COMMIT
```

When directly comparing the `id` column to a single value, the query planner produces a much faster query plan. It uses an index scan to find the matching row, before checking if that row satisfies the corresponding `workspace_members` row requirement. This is definitely much better than the sequential scan.

However, if you want to perform a query selecting all the `workspace_members` that satisfy the RLS policy conditions, you can't just provide a single ID for an equality comparison. The somewhat ugly workaround here is to specify the RLS policy condition again, this time as a `where` condition for the query:

```sql
postgres=# begin;
set local role authenticated_user;
set local "rls.user_id" to 'a74c6f1e-b6ac-4088-b468-6c1987146721';

explain analyze
select * from users
where exists (
  select 1 from workspace_members
  where workspace_members.user_id = users.id
);
end;
BEGIN
SET
SET
                                                                      QUERY PLAN
----------------------------------------------------------------------------------------------------------------------------------------------------------
 Nested Loop  (cost=219.88..1429.30 rows=24 width=61) (actual time=0.211..0.295 rows=13 loops=1)
 InitPlan 5 (returns $4)
   ->  ProjectSet  (cost=0.00..0.32 rows=10 width=16) (actual time=0.110..0.116 rows=3 loops=1)
         ->  Result  (cost=0.00..0.01 rows=1 width=0) (actual time=0.000..0.001 rows=1 loops=1)
 ->  HashAggregate  (cost=219.15..219.64 rows=49 width=16) (actual time=0.147..0.150 rows=13 loops=1)
       Group Key: workspace_members.user_id
       Batches: 1  Memory Usage: 24kB
       ->  Bitmap Heap Scan on workspace_members  (cost=44.59..219.03 rows=49 width=16) (actual time=0.130..0.143 rows=15 loops=1)
             Recheck Cond: (workspace_id = ANY ($4))
             Heap Blocks: exact=15
             ->  Bitmap Index Scan on workspace_members_workspace_id_idx  (cost=0.00..44.58 rows=49 width=0) (actual time=0.128..0.128 rows=15 loops=1)
                   Index Cond: (workspace_id = ANY ($4))
 ->  Index Scan using users_pkey on users  (cost=0.42..24.68 rows=1 width=61) (actual time=0.011..0.011 rows=1 loops=13)
       Index Cond: (id = workspace_members.user_id)
       Filter: (SubPlan 2)
       SubPlan 2
         ->  Bitmap Heap Scan on workspace_members workspace_members_1  (cost=4.76..16.49 rows=1 width=0) (actual time=0.008..0.008 rows=1 loops=13)
               Recheck Cond: (user_id = users.id)
               Filter: (workspace_id = ANY ($1))
               Rows Removed by Filter: 1
               Heap Blocks: exact=26
               InitPlan 1 (returns $1)
                 ->  ProjectSet  (cost=0.00..0.32 rows=10 width=16) (actual time=0.043..0.047 rows=3 loops=1)
                       ->  Result  (cost=0.00..0.01 rows=1 width=0) (actual time=0.000..0.000 rows=1 loops=1)
               ->  Bitmap Index Scan on workspace_members_user_id_idx  (cost=0.00..4.44 rows=3 width=0) (actual time=0.002..0.002 rows=3 loops=13)
                     Index Cond: (user_id = users.id)
 Planning Time: 0.284 ms
 Execution Time: 0.396 ms
(28 rows)

COMMIT
```

<aside>
🤯! Using RLS can make your query plans really massive and difficult to read. If you prefer, there are graphical tools which might be easier to understand.
</aside>

Now, instead of a sequential scan on `users`, a nested loop is performed instead. First, all viewable `workspace_members` are obtained in the `HashAggregate` node, then an index scan is performed for each one to find the corresponding user using an index scan. There is however some duplicate work performed: after getting the corresponding user via the index scan, the RLS policy condition for the corresponding `workspace_members` is executed again for each user. Given different relationships and dependency patterns within the data, it might be optimal to just use the sequential scan instead.

## PostgREST-specific: Considering storing data in a separate schema and using views to access data {#postgrest}

Using an API layer like PostgREST makes it easy to create custom queries to the database. At the same time, it's also easy to send unperformant queries to the database. If you're allowing PostgREST full access to your tables, it's difficult to prevent unperformant queries from being executed (whether intentionally or unintentionally).

One way would be to [store data in a completely separate schema](https://postgrest.org/en/stable/explanations/db_authz.html#schemas) to the schema which PostgREST is granted access. For example, instead of creating tables in the `public` schema, create tables in a new `private` schema and use views or functions to return records:

```sql
-- Create new private schema.
postgres=# create schema private;
CREATE SCHEMA

postgres=# grant usage on schema private to authenticated_user;
GRANT

-- Create new private view.
postgres=#
create view private.users
-- Security invoker views enforce RLS policies for the user
-- accessing the view instead
with (security_invoker=on)
as select * from users;
CREATE VIEW

postgres=# grant select on private.users to authenticated_user;
GRANT
```

This allows you to choose which tables can be queried using the API. By opting in to exposing specific tables to public API access, you can be more aware of the potential failure paths and mitigate the risk of getting unexpected slowdowns.

You can also add additional `where` conditions to the view definitions, to "hint" to Postgres to use a better query plan:

```sql
create view public.users as
  select * from private.users
  where id in private.get_accessible_user_ids();
```

## Conclusion

Here's a brief summary on the main points to take note of when writing RLS policies:

- Test your query performance using a role which does not bypass RLS.
- Ensure that you have created appropriate indices (usually on commonly filtered columns or columns which are part of a join condition, e.g. foreign key references).
- It's likely you'll need to use security definer functions within your policies at some point to avoid infinite recursion in more complicated schemas. If you're using any functions, ensure that:
  - Functions used in RLS policies should try not to accept column values as arguments to avoid doing full table scans.
  - Security definer functions are defined as accurately as possible (function stability/volatility and estiamted number of rows returned).
- Use uncorrelated subqueries if possible, since they can be extracted out into `InitPlan` nodes which are executed at the start of the query.
- Non-leakproof functions and operators causes can prevent index scans.
- For subquery expressions:
  - Instead of `any` subqueries (`id in (select get_valid_ids())` or `id in any(select get_valid_ids())`), use an array comparison subquery: `id in any(array(select get_valid_ids))`.
  - For `exists` subqueries, you can "hint" to the query planner to avoid sequential scans by adding additional `where` conditions.
- If you're using PostgREST, consider storing tables in a separate private schema and using views to access data.
- Of course, as all performance advice goes: your mileage might vary. Do test the query performance before and after making any changes to RLS policies and indices.

Whew! We've finally reached the end of the post! That's really quite a lot to take in. So, perhaps, now you're thinking: should I use RLS for my next project? Well, if you want to learn more about Postgres than you'd ever need to know, then yes 🫠! Otherwise, it depends.

If you're working on a project which doesn't have much complex backend logic, it's definitely worth using Postgres with RLS policies and an API server like PostgREST. That stack allows you to really focus and iterate on the product instead of more banal tasks like writing custom API endpoints. Just keep an eye out for the stats—if RLS starts to become too much of a drag on your app's query loading times, it might be time to consider a custom backend without RLS.

Personally, I think RLS is a really underappreciated feature, and it's great to have such a mechanism natively integrated into Postgres. Ideally, as tools like PostgREST and Supabase advocate for it, RLS can gain in popularity and invite more contributors to optimize it, so that we no longer need to choose between safety and performance when using Postgres.

## References

The following pages were helpful in allowing me to gain a better understanding of RLS and Postgres internals:

- [Notes on PostgreSQL row level security by Simon Strassl](https://sigmoid.at/post/2021/09/23/postgresql_row_level_security/)
- [Postgres 13 Row-Level Security Performance](https://jeffchen.dev/posts/Postgres-13-Row-Level-Security-Performance/): Comparison of query optimization methods
- [The Internals of PostgreSQL by Hironobu Suzuki](https://www.interdb.jp/pg/index.html): A really thorough book describing Postgres internals with diagrams and source code references
- [5mins of Postgres E28: Row Level Security in Postgres, security invoker views and why LEAKPROOF functions matter by Lukas Fittl](https://pganalyze.com/blog/5mins-postgres-row-level-security-bypassrls-security-invoker-views-leakproof-functions): Quick review of various references about RLS, views and leakproof functions

[^1]: [Supabase](https://supabase.com/) is an all-in-one database platform based on Postgres. It integrates native PostgreSQL features like RLS alongside additional tooling like PostgREST and a custom authentication server to create a convenient platform of services for developers.
[^2]: `update` and `delete` statements are less prone to suffering from similar performance drawbacks, simply because they operate (or should operate!) on rows uniquely identified by their primary keys, which are indexed by default.
[^3]: See [this article](https://medium.com/@awesboss/how-to-find-missing-indexes-on-foreign-keys-2faffd7e6958) to find foreign key references which might need indices.
[^4]: The `any` subquery which would run as a subplan executing for every row, is [converted into a hashed subplan](https://github.com/postgres/postgres/blob/8382864eb5c9f9ebe962ac20b3392be5ae304d23/src/backend/optimizer/plan/subselect.c#L510-L516). This means the result of the subquery is hashed to avoid having to be executed repeatedly.
